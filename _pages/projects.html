---
layout: archive
title: "Projects"
permalink: /talks/
author_profile: true
---

<h2><span style="background-color: #ffffff;">Soft catching an object in flight</span></h2>
<p style="color: #000000; font-family: Verdana,Helvetica,Arial,Geneva,Swiss,SunSans-Regular,sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-decoration: none; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; word-spacing: 0px; padding: 0px; margin: 0px 0px 4px 0px;">Catching a fast flying object is particularly challenging as consists of two tasks: it requires extremely precise estimation of the object's motion and control of the robot motion. Any small imprecision may lead the fingers to close too abruptly and let the object fly away from the hand before closing. We present a strategy to overcome for sensori-motor imprecision by introducing softness in the catching approach. Soft catching consists of having the robot moves with the object for a short period of time, so as to leave more time for the fingers to close on the object. We use a dynamical systems (DS) based control law to generate the appropriate reach and follow motion, which is expressed as a Linear Parameter Varying (LPV) system. We propose a method to approximate the parameters of LPV systems using Gaussian Mixture Models, based on a set of kinematically feasible demonstrations generated by an off-line optimal control framework. We show theoretically that the resulting DS will intercept the object at the intercept point, at the right time with the desired velocity direction.<br /></span></p>
<p><iframe src="https://www.youtube.com/embed/FxvVJzb61js" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Coordinated multi-arm motion planning: Reaching for moving objects in the face of uncertainty</h2>
<p style="color: #000000; font-family: Verdana,Helvetica,Arial,Geneva,Swiss,SunSans-Regular,sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-decoration: none; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; word-spacing: 0px; padding: 0px; margin: 0px 0px 4px 0px;">Coordinated control strategies for multi-robot systems are necessary for tasks that cannot be executed by a single robot. This encompasses tasks where the workspace of the robot is too small or where the load is too heavy for one robot to handle. Using multiple robots makes the task feasible by extending the workspace and/or increase the payload of the overall robotic system. In this paper, we consider two instances of such task: a co-worker scenario in which a human hands over a large object to a robot; intercepting a large flying object. The problem is made difficult as the pick-up/intercept motions must take place while the object is in motion and because the object's motion is not deterministic. The challenge is then to adapt the motion of the robotic arms in coordination with one another and with the object. Determining the pick-up/intercept point is done by taking into account the workspace of the multi-arm system and is continuously recomputed to adapt to change in the object's trajectory. We propose a dynamical systems (DS) based control law to generate autonomous and synchronized motions for a multi-arm robot system in the task of reaching for a moving object. We show theoretically that the resulting DS coordinates the motion of the robots with each other and with the object, while the system remains stable. We validate our approach on a dual-arm robotic system and demonstrate that it can re-synchronize and adapt the motion of each arm in synchrony in a fraction of seconds, even when the motion of the object is fast and not accurately predictable.</p>
<p><iframe src="https://www.youtube.com/embed/UfucwRGa7k8" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>A Unified Framework for Coordinated Multi-Arm Motion Planning</h2>
<p style="color: #000000; font-family: Verdana,Helvetica,Arial,Geneva,Swiss,SunSans-Regular,sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-decoration: none; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; word-spacing: 0px; padding: 0px; margin: 0px 0px 4px 0px;">Coordination is essential in the design of dynamic control strategies for multi-arm robotic systems. Given the complexity of the task and dexterity of the system, coordination constraints can emerge from different levels of planning and control. Primarily, one must consider task-space coordination, where the robots must coordinate with each other, with an object or with a target of interest. Coordination is also necessary in joint-space, as the robots should avoid self-collisions at any time. Moreover, multi-arm task-space behaviors can either be synchronous or asynchronous. In this work, we define a synchronous behavior as that in which the robot arms must coordinate with each other and with a moving object such that they reach for it in synchrony. Whereas, an asynchronous behavior allows for each robot to perform independent point-to-point reaching motions. In this paper, we build upon our previous work on coordinated multi-arm control (Salehian et al. 2016a), to propose a unified framework that endows a multi-arm system with both synchronous and asynchronous behaviors and the capability of smoothly transitioning between them, whilst avoiding self-collisions. To provide such smooth transitioning, we introduce the notion of synchronization allocation. Given the motion of the object and the joint workspace of the multi-arm system, each arm is being continuously allocated to a desired behavior. While being allocated to the synchronous behavior, control of the robots is taken over by the virtual object Dynamical System (DS), which exploits the notion of a virtual object, whose dynamics is coupled to that of the robot&rsquo;s motions. While allocated to the asynchronous behavior, the robots are controlled independently, each with their own goal-directed stable DS. Both behaviors and their synchronization allocation are encoded in a single dynamical system. Further, we provide coordination in joint-space by introducing a centralized inverse kinematics (IK) solver under self-collision avoidance constraints; formulated as a quadratic program (QP) and solved in real-time. The space of free motion is modeled through a sparse non-linear kernel classification method in a data-driven learning approach. We validate our framework on a dual-arm robotic system and demonstrate that it can re-synchronize and adapt the motion of each arm within milliseconds, even when the motion of the object is fast and not accurately predictable.</p>
<p><iframe src="https://www.youtube.com/embed/LxAWvU2locU" width="280" height="200" frameborder="0" allowfullscreen="allowfullscreen"></iframe> <iframe src="https://www.youtube.com/embed/T23rlHeFtkc" width="280" height="200" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>A DS Based Approach for Controlling Robotic Manipulators During Non-contact/Contact Transitions</h2>
<p style="color: #000000; font-family: Verdana,Helvetica,Arial,Geneva,Swiss,SunSans-Regular,sans-serif; font-size: 12px; font-style: normal; font-variant: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: left; text-decoration: none; text-indent: 0px; text-transform: none; -webkit-text-stroke-width: 0px; white-space: normal; word-spacing: 0px; padding: 0px; margin: 0px 0px 4px 0px;">Many daily life tasks require precise control when making contact with surfaces. Ensuring a smooth transition from free motion to contact is crucial as incurring a large impact force may lead to unstable contact with the robot bouncing on the surface, i.e. chattering. Stabilizing the forces at contact is not possible as the impact lasts less than a millisecond, leaving no time for the robot to react to the impact force. We present a strategy in which the robot adapts its dynamic before entering into contact. The speed is modulated so as to align with the surface. We leverage the properties of autonomous dynamical systems for immediate re-planning and handling unforeseen perturbations and exploit local modulations of the dynamics to control for the smooth transitions at contact. We show theoretically and empirically that by using the modulation framework, the robot can (I) stably touch the contact surface, even when the surface's location is uncertain, (II) at a desired location, and finally (III) leave the surface or stop on the surface at a desired point.</p>
<iframe width="280" height="200" src="https://www.youtube.com/embed/fhfBBMH4XVg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="280" height="200" src="https://www.youtube.com/embed/AkKpmdGjAa8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>&nbsp;</p>
<p>&nbsp;</p>